{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdwfqzhFdxxU"
      },
      "source": [
        "### Necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "784Mmk2Ld-di",
        "outputId": "677c6b4e-8afe-4533-d2f2-e6c03537def8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spafe in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from spafe) (1.21.5)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from spafe) (1.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install spafe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BdtUn4Lgdxxb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from spafe.utils import vis\n",
        "from spafe.features.lpc import lpc, lpcc\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcsyUEzfdxxd"
      },
      "source": [
        "## Silence removal algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zHtsJSQxdxxd"
      },
      "outputs": [],
      "source": [
        "def silence_removing(y, sr):\n",
        "\n",
        "  #I calculate the mean and standard deviation for the first 1600 samples\n",
        "  test = y[:1600]\n",
        "  stand_dev = np.std(test)\n",
        "  mean = np.mean(test)  \n",
        "\n",
        "  x= np.zeros((y.shape))\n",
        "\n",
        "  #I check if the value of the one-dimensional Mahalanobis distance function is greater than 3 \n",
        "  # This is the detection of voice and non-voice parts\n",
        "  for i in range(0,x.shape[0]):\n",
        "    if (abs(y[i]-mean))/stand_dev > 3:\n",
        "      x[i] = 1\n",
        "    else:\n",
        "      x[i] = 0\n",
        "\n",
        "  frame_size = int(sr/100)\n",
        "  lista = np.split(x,range(frame_size,x.shape[0],frame_size))\n",
        "\n",
        "  arr_numb = int(math.ceil(len(x)/(sr/100.0)))\n",
        "  probes_numb = int(math.ceil(sr/100))\n",
        "  temp_arr= np.zeros((arr_numb,probes_numb))\n",
        "  index = 0 \n",
        "\n",
        "  for arr in lista:\n",
        "    index += 1\n",
        "    zeros = 0\n",
        "    ones = 0\n",
        "    for i in arr:\n",
        "      if i == 0:\n",
        "        zeros += 1\n",
        "      if i == 1:\n",
        "        ones += 1\n",
        "    if zeros + ones == probes_numb:\n",
        "      if zeros > ones:\n",
        "        for i in range(0,probes_numb):\n",
        "          if arr[i] == 1:\n",
        "            temp_arr[index-1][i] = 0\n",
        "      if ones >= zeros:\n",
        "        for i in range(0,probes_numb):\n",
        "          temp_arr[index-1][i] = 1\n",
        "\n",
        "  one_temp_arr = temp_arr.flatten()\n",
        "\n",
        "  result = list()\n",
        "  for i in range(0,len(x)):\n",
        "    if one_temp_arr[i] == 1:\n",
        "      result.append(y[i])\n",
        "  result=np.array(result)\n",
        "\n",
        "  return result, sr "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtAZWzvfdxxf"
      },
      "source": [
        "## Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BmyynaHBdxxg"
      },
      "outputs": [],
      "source": [
        "def extract_features(index, row, data):\n",
        "\n",
        "   src = '/content/drive/MyDrive/clips/' + data['path'][index]\n",
        "   X, sample_rate = librosa.load(src, sr=None)\n",
        "   \n",
        "   # Removal of non-voiced portions\n",
        "   X, sample_rate = silence_removing(X, sample_rate)\n",
        "\n",
        "   # Generating the Mel frequency cepstral coefficients (MFCC) from the time series\n",
        "   mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "\n",
        "   # Lpcs calculation\n",
        "   lpcs = lpc(sig=X, fs=sample_rate, num_ceps=20)\n",
        "\n",
        "   # Lpccs calculation\n",
        "   lpccs = lpcc(sig=X, fs=sample_rate, num_ceps=20, normalize = True)\n",
        "\n",
        "   # Calculating the chromatogram from the run of the power spectrogram.\n",
        "   stft = np.abs(librosa.stft(X)) # Generates a Short-time Fourier transform (STFT) to use in the chroma_stft\n",
        "   chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
        "\n",
        "   # Computing the spectogram on the Mel scale\n",
        "   mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T, axis=0)\n",
        "\n",
        "   # Calculation of spectral contrast\n",
        "   contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "\n",
        "   # Calculation of the tonal features of the center of gravity of the spectrum (tonnetz)\n",
        "   tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
        "\n",
        "   # Calculation of spectral features\n",
        "   spectral = list()\n",
        "   spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=X, sr=sample_rate)) # środek ciężkości widma\n",
        "   spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=X, sr=sample_rate)) #pasmo widmowe\n",
        "   spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=X, sr=sample_rate)) # spadek widmowy\n",
        "   spectral.append(spectral_centroid)\n",
        "   spectral.append(spectral_bandwidth)\n",
        "   spectral.append(spectral_rolloff)\n",
        "\n",
        "   return mfccs, chroma, mel, contrast, tonnetz, spectral"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzP3v2BPdxxh"
      },
      "source": [
        "Reading the previously saved csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPvBOHpUejl0",
        "outputId": "e4e9d96a-d292-449b-fffe-96cd4fb49eec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "fHLmz9H0dxxh"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/SpeakerRecognition/data.csv', sep=',') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1trAV6mBdxxi"
      },
      "source": [
        "Feature extraction for each recording"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYx1QVmOdxxj",
        "outputId": "86d7376a-1265-472e-bc6b-7dbf301c2de7"
      },
      "outputs": [],
      "source": [
        "features = list()\n",
        "for index, row in data.iterrows():\n",
        "  features.append(extract_features(index, row, data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmpVsDx2dxxk"
      },
      "source": [
        "Saving the extracted features due to the time-consuming nature of the process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuifnmyCdxxk",
        "outputId": "37d156f7-1bbf-45d1-dfb2-d28b47e2cf79"
      },
      "outputs": [],
      "source": [
        "np.save('/content/drive/MyDrive/SpeakerRecognition/features', features)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "feature_extraction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
