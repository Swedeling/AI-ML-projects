{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QdwfqzhFdxxU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "784Mmk2Ld-di",
    "outputId": "677c6b4e-8afe-4533-d2f2-e6c03537def8",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install spafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BdtUn4Lgdxxb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spafe.features.lpc import lpc, lpcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcsyUEzfdxxd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Silence removal algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zHtsJSQxdxxd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def silence_removing(y, sr):\n",
    "\n",
    "  #I calculate the mean and standard deviation for the first 1600 samples\n",
    "  test = y[:1600]\n",
    "  stand_dev = np.std(test)\n",
    "  mean = np.mean(test)  \n",
    "\n",
    "  x= np.zeros((y.shape))\n",
    "\n",
    "  #I check if the value of the one-dimensional Mahalanobis distance function is greater than 3 \n",
    "  # This is the detection of voice and non-voice parts\n",
    "  for i in range(0,x.shape[0]):\n",
    "      x[i] = 1 if (abs(y[i]-mean))/stand_dev > 3 else 0\n",
    "\n",
    "  frame_size = int(sr/100)\n",
    "  lista = np.split(x,range(frame_size,x.shape[0],frame_size))\n",
    "\n",
    "  arr_numb = int(math.ceil(len(x)/(sr/100.0)))\n",
    "  probes_numb = int(math.ceil(sr/100))\n",
    "  temp_arr= np.zeros((arr_numb,probes_numb))\n",
    "  index = 0 \n",
    "\n",
    "  for arr in lista:\n",
    "    index += 1\n",
    "    zeros, ones = 0, 0\n",
    "    for i in arr:\n",
    "      if i == 0:\n",
    "        zeros += 1\n",
    "      if i == 1:\n",
    "        ones += 1\n",
    "    if zeros + ones == probes_numb:\n",
    "      if zeros > ones:\n",
    "        for i in range(0,probes_numb):\n",
    "          if arr[i] == 1:\n",
    "            temp_arr[index-1][i] = 0\n",
    "      if ones >= zeros:\n",
    "        for i in range(0,probes_numb):\n",
    "          temp_arr[index-1][i] = 1\n",
    "\n",
    "  one_temp_arr = temp_arr.flatten()\n",
    "\n",
    "  result = list()\n",
    "  for i in range(0,len(x)):\n",
    "    if one_temp_arr[i] == 1:\n",
    "      result.append(y[i])\n",
    "  result=np.array(result)\n",
    "\n",
    "  return result, sr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtAZWzvfdxxf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "BmyynaHBdxxg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(index, data):\n",
    "\n",
    "   src = '/content/drive/MyDrive/clips/' + data['path'][index]\n",
    "   X, sample_rate = librosa.load(src, sr=None)\n",
    "   \n",
    "   # Removal of non-voiced portions\n",
    "   X, sample_rate = silence_removing(X, sample_rate)\n",
    "\n",
    "   # Generating the Mel frequency cepstral coefficients (MFCC) from the time series\n",
    "   mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "\n",
    "   # Lpcs calculation\n",
    "   lpcs = lpc(sig=X, fs=sample_rate, num_ceps=20)\n",
    "\n",
    "   # Lpccs calculation\n",
    "   lpccs = lpcc(sig=X, fs=sample_rate, num_ceps=20, normalize = True)\n",
    "\n",
    "   # Calculating the chromatogram from the run of the power spectrogram.\n",
    "   stft = np.abs(librosa.stft(X)) # Generates a Short-time Fourier transform (STFT) to use in the chroma_stft\n",
    "   chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "\n",
    "   # Computing the spectogram on the Mel scale\n",
    "   mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T, axis=0)\n",
    "\n",
    "   # Calculation of spectral contrast\n",
    "   contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "\n",
    "   # Calculation of the tonal features of the center of gravity of the spectrum (tonnetz)\n",
    "   tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "\n",
    "   # Calculation of spectral features\n",
    "   spectral = list()\n",
    "   spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=X, sr=sample_rate)) # środek ciężkości widma\n",
    "   spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=X, sr=sample_rate)) #pasmo widmowe\n",
    "   spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=X, sr=sample_rate)) # spadek widmowy\n",
    "   spectral.append(spectral_centroid)\n",
    "   spectral.append(spectral_bandwidth)\n",
    "   spectral.append(spectral_rolloff)\n",
    "\n",
    "   return mfccs, chroma, mel, contrast, tonnetz, spectral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzP3v2BPdxxh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Reading the previously saved csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XPvBOHpUejl0",
    "outputId": "e4e9d96a-d292-449b-fffe-96cd4fb49eec",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "fHLmz9H0dxxh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/drive/MyDrive/SpeakerRecognition/data.csv', sep=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1trAV6mBdxxi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Feature extraction for each recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYx1QVmOdxxj",
    "outputId": "86d7376a-1265-472e-bc6b-7dbf301c2de7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features = list()\n",
    "for index, row in data.iterrows():\n",
    "  features.append(extract_features(index, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmpVsDx2dxxk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Saving the extracted features due to the time-consuming nature of the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XuifnmyCdxxk",
    "outputId": "37d156f7-1bbf-45d1-dfb2-d28b47e2cf79",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.save('/content/drive/MyDrive/SpeakerRecognition/features', features)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "feature_extraction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}